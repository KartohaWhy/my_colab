{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KartohaWhy/my_colab/blob/main/Copy_Encoder_decoder_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  –ü—Ä–∞–∫—Ç–∏–∫–∞ –ø–æ —Ä–∞–±–æ—Ç–µ —Å –≠–Ω–∫–æ–¥–µ—Ä–∞–º–∏"
      ],
      "metadata": {
        "id": "_AOOjGBvtP38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –º—ã –ø–æ—Ç—Ä–µ–Ω–∏—Ä—É–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç–Ω–∫–æ–¥–µ—Ä—ã –ø–æ–¥ –Ω–∞—à–∏ –∑–∞–¥–∞—á–∏. –ú—ã –ø–æ—Ä–∞–±–æ—Ç–∞–µ–º —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–π –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ñ–∏–ª—å–º—ã, –ø–æ–ø—Ä–æ–±—É–µ–º —É—Å–ª–æ–∂–Ω–∏—Ç—å –∏ –≤—ã–π—Ç–∏ –Ω–∞ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤—É—é –∑–∞–¥–∞—á—É, –∞ –ø–æ—Å–ª–µ - –ø–æ–¥–∫–ª—é—á–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ —Ñ–∏–ª—å–º–æ–≤ –ø–æ –∏—Ö –æ–ø–∏—Å–∞–Ω–∏—é."
      ],
      "metadata": {
        "id": "R3NteXJrtUdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"
      ],
      "metadata": {
        "id": "SFAqdV4v_3_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets transformers"
      ],
      "metadata": {
        "id": "StLV9K1sC-US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "DJFr4QE6C70X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–µ—Ä–µ–¥ –≤–∞–º–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ BERT. –ú—ã –±—É–¥–µ–º —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ñ–∏–ª—å–º—ã ‚Äî **–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π** –æ—Ç–∑—ã–≤ –∏–ª–∏ **–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π**.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç [IMDb](https://huggingface.co/datasets/stanfordnlp/imdb) –æ—Ç [Stanford NLP](https://nlp.stanford.edu/), —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 50‚ÄØ000 –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö —Ä–µ—Ü–µ–Ω–∑–∏–π, —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –≤—Ä—É—á–Ω—É—é. –¶–µ–ª—å ‚Äî –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–ø–æ—Å–æ–±–Ω—É—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –ø–æ –∏—Ö —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–µ. –í—ã –ø—Ä–æ–π–¥—ë—Ç–µ –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞: –æ—Ç –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞."
      ],
      "metadata": {
        "id": "DJnnmwz1AV5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ –º—ã –¥–≤–∏–Ω–µ–º—Å—è –¥–∞–ª—å—à–µ, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∫–ª—é—á–µ–Ω –∏–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω GPU –≤ colab. –†–∞–±–æ—Ç–∞ —Å BERT –ø–æ—Ç—Ä–µ–±—É–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤, –Ω–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –≤–µ—Å—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –∫–æ–¥, –∞ –ø–æ—Ç–æ–º —É–∂–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å GPU –ø–µ—Ä–µ–¥ —Å–∞–º—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏. –°–æ–≤–µ—Ç—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—É—é –≤ colab Tesla T4."
      ],
      "metadata": {
        "id": "E88AC_Vvu3z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU –Ω–∞ –º–µ—Å—Ç–µ: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "92FbwW-ovOde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oPy65CbFkpCd"
      },
      "outputs": [],
      "source": [
        "# –¥–∞—Ç–∞—Å–µ—Ç —Å—Ä–∞–∑—É –ø–æ–¥–≥—Ä—É–∂–µ–Ω –≤ –º–æ–¥—É–ª—å datasets –æ—Ç HF\n",
        "\n",
        "dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "2HKNhUOgEZH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú—ã –≤–∏–¥–∏–º, —á—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É, –∞ —Ç–∞–∫–∂–µ \"unsupervised\" –Ω–∞–±–æ—Ä - –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö ‚Äî —Ç–æ –µ—Å—Ç—å –æ—Ç–∑—ã–≤—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –º–µ—Ç–∫–∏ (label –Ω–µ –Ω–µ—Å—ë—Ç –æ–±—É—á–∞—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏).\n",
        "\n",
        "* –í —á–∞—Å—Ç–∏ `train` –∏ `test` —É –∫–∞–∂–¥–æ–≥–æ –æ—Ç–∑—ã–≤–∞ –µ—Å—Ç—å –º–µ—Ç–∫–∞: `label = 0` (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π) –∏–ª–∏ `label = 1` (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π).\n",
        "* –í —á–∞—Å—Ç–∏ `unsupervised` –∫–æ–ª–æ–Ω–∫–∞ `label` –µ—Å—Ç—å, –Ω–æ –µ—ë –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ‚Äî –æ–Ω–æ –ª–∏–±–æ –ø—É—Å—Ç–æ–µ, –ª–∏–±–æ —Ñ–∏–∫—Ç–∏–≤–Ω–æ–µ (`-1`), —Ç–∞–∫ –∫–∞–∫ —ç—Ç–∞ —á–∞—Å—Ç—å –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è:\n",
        "\n",
        "  * –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, pretraining),\n",
        "  * —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏,\n",
        "  * –ø–æ–ª—É- –∏–ª–∏ —Å–ª–∞–±–æ—Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è."
      ],
      "metadata": {
        "id": "_D3oqcxuFAXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"unsupervised\"][0] # –ª–µ–π–±–ª –æ–±–æ–∑–Ω–∞—á–µ–Ω –∫–∞–∫ \"-1\""
      ],
      "metadata": {
        "id": "0HV8qyOpFjBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í –Ω–∞—à–µ–π –∑–∞–¥–∞—á–µ –º—ã –Ω–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `unsupervised` —á–∞—Å—Ç—å ‚Äî —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ `train` –∏ `test`. –¢–æ—á–Ω–µ–µ, —Ç–æ–ª—å–∫–æ –∏–∑ `train` - 50.000 –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ –¥–ª—è —É—á–µ–±–Ω–æ–π –∑–∞–¥–∞—á–∏ –¥–æ–ª–≥–æ–≤–∞—Ç–æ. –° —Ü–µ–ª—å—é —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ - —Å–æ–∫—Ä–∞—Ç–∏–º –∏ –¥–∞—Ç–∞—Å–µ—Ç."
      ],
      "metadata": {
        "id": "UbxIx2tlGGZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 1.** –î–∞–≤–∞–π—Ç–µ –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ `train`, –∞ –∑–∞—Ç–µ–º –ø–µ—Ä–µ–º–µ—à–∞–µ–º –µ–≥–æ —Å –ø–æ–º—â—å—é `shuffle`, –∞ –ø–æ—Å–ª–µ —Ä–∞–∑–æ–±—å–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏ –≤ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 80:20.\n",
        "\n",
        "> –ü–æ–ø—Ä–æ–±—É–µ–º —É–¥–µ—Ä–∂–∞—Ç—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤? –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤. –ï—Å–ª–∏ –Ω–µ –ø–æ–º–Ω–∏—Ç–µ, –∫–∞–∫ —ç—Ç–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å, –∑–∞–≥–ª—è–Ω–∏—Ç–µ –≤ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ],
      "metadata": {
        "id": "cdsUwKz_GZW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥\n",
        "# „ÉΩ(‚ô°‚Äø‚ô°)„Éé\n",
        "\n",
        "train_data = dataset[\"train\"].to_pandas()\n",
        "shuffled_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "train_df, val_df, = train_test_split(\n",
        "    shuffled_data,\n",
        "    test_size=0.2,\n",
        "    stratify=shuffled_data['label'],  # –í–∞–∂–Ω–æ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤\n",
        ")"
      ],
      "metadata": {
        "id": "tDXGDov7Hani"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBClfwU6dnYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "ZvOfa29iduG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df"
      ],
      "metadata": {
        "id": "lawAVLLPrv26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ7xbPXSzacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–æ–ø—Ä–æ—Å 1.** –°–∫–æ–ª—å–∫–æ –æ—Ç–∑—ã–≤–æ–≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ `(label = 1)` —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ `val_df` –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è?"
      ],
      "metadata": {
        "id": "6PiD3_6tL9aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 2.** **–ê —Å—Ç–æ–∏—Ç –ª–∏ —á–∏—Å—Ç–∏—Ç—å –æ—Ç–∑—ã–≤—ã?**"
      ],
      "metadata": {
        "id": "XvqzvD2URSQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, –≤ –∫–∞–∫–æ–º –≤–∏–¥–µ –ø—Ä–∏—Ö–æ–¥—è—Ç —Ç–µ–∫—Å—Ç—ã, –∏ –Ω—É–∂–Ω–∞ –ª–∏ –∏–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞.\n",
        "\n",
        "–í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –æ—Ç–∑—ã–≤—ã –≤–∑—è—Ç—ã –Ω–∞–ø—Ä—è–º—É—é –∏–∑ `IMDb` ‚Äî –æ–Ω–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã –∂–∏–≤—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏. –ß—Ç–æ–±—ã –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ–± –æ—á–∏—Å—Ç–∫–µ, –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
        "\n",
        "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞:\n",
        "\n",
        "* –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤,\n",
        "* –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é (–º–Ω–æ–≥–æ –ª–∏ –µ—ë? –Ω–∞—Ä—É—à–∞–µ—Ç –ª–∏ –æ–Ω–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ?),\n",
        "* —Ü–∏—Ñ—Ä—ã –∏ HTML-—Ç–µ–≥–∏ (–≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –ª–∏? –Ω—É–∂–Ω—ã –ª–∏ –æ–Ω–∏ –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏?),\n",
        "* —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–º–æ–≥—É—Ç –ª–∏ –æ–Ω–∏ –º–µ—à–∞—Ç—å?)."
      ],
      "metadata": {
        "id": "QMqoi7f7SS_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –ø–µ—Ä–≤—ã–µ –¥–µ—Å—è—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∏ –±–æ–ª—å—à–µ) –∏ –ø–æ–∏–∑—É—á–∞–π—Ç–µ –∏—Ö\n",
        "\n",
        "# –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥\n",
        "# (Ôº†_Ôº†)\n",
        "\n",
        "X_train[:10]"
      ],
      "metadata": {
        "id": "IORsy3WnSdBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–æ–ø—Ä–æ—Å 2** - –Ω–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ: *–ö–∞–∫—É—é –±–∞–∑–æ–≤—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –≤—ã –±—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏ –∫ —ç—Ç–∏–º –æ—Ç–∑—ã–≤–∞–º –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä BERT?*\n",
        "\n",
        "> *–í–∞–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å*: –º–æ–¥–µ–ª–∏ `BERT` –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ —Å—ã—Ä—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö, –Ω–æ –ª–µ–≥–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å—ë –∂–µ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å ‚Äî –æ—Å–æ–±–µ–Ω–Ω–æ, –µ—Å–ª–∏ –º—ã –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç, —Å—á–∏—Ç–∞–µ–º TF-IDF –∏–ª–∏ —Ö–æ—Ç–∏–º —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑.\n",
        "\n",
        "–í —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ –≤—ã –Ω–∞–ø–∏—à–µ—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ —ç—Ç–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ –Ω—É–∂–Ω—ã, –≤—Å—ë —Ä–∞–≤–Ω–æ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∏—Ö. –í –±–æ–Ω—É—Å–Ω–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É –∏ –ø–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ."
      ],
      "metadata": {
        "id": "NiElShYWS-e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 3.** –¢–µ–ø–µ—Ä—å –ø–æ—á–∏—Å—Ç–∏–º –Ω–∞—à–∏ —Ç–µ–∫—Å—Ç—ã. –ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `clean_text`, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ—á–∏—â–∞—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–µ–≥–æ. –í—ã –º–æ–∂–µ—Ç–µ –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –∫–æ–¥ —Å —Å–µ–º–∏–Ω–∞—Ä–∞ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç. –î–∞–≤–∞–π—Ç–µ: 1) –ø—Ä–∏–≤–µ–¥–µ–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É 2) —É–±–µ—Ä–µ–º —á–∏—Å–ª–∞ 3) —É–¥–∞–ª–∏–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ 4) —É–±–µ—Ä–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞.\n",
        "\n",
        "–¢–∞–∫–∂–µ —É–¥–∞–ª–∏—Ç–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã —Ç–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –æ–∫–∞–∑–∞–ª—Å—è –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.\n",
        "\n",
        "–í–∞–º –∑–¥–µ—Å—å –ø—Ä–∏–≥–æ–¥—è—Ç—Å—è –º–æ–¥—É–ª–∏ `re`, `string`, `nltk` (`nltk.download('stopwords')`), `stopwords` –∏–∑ `nltk.corpus`. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –∫ —Ç—Ä–µ–π–Ω—É, –∏ –∫ —Ç–µ—Å—Ç—É."
      ],
      "metadata": {
        "id": "SPI-y8rSTXCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # —Ä–∞–±–æ—Ç–∞ —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞)\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "eFQnAY4piPdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥\n",
        "# (‚åí_‚åí;)\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
        "    text = re.sub('\\n', ' ', text)  # –£–¥–∞–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫\n",
        "    text = re.sub('\\d+', '', text)  # –£–¥–∞–ª–µ–Ω–∏–µ —Ü–∏—Ñ—Ä\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
        "    return text"
      ],
      "metadata": {
        "id": "4q4H614dS9jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏\n",
        "val_df.dropna()\n",
        "train_df.dropna()\n",
        "# –°—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "train_df['Cleaned'] = train_df['text'].apply(clean_text)\n",
        "val_df['Cleaned'] = val_df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "XJxHNaqjihJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–æ–ø—Ä–æ—Å 3.** –ß–µ–º—É —Ä–∞–≤–Ω–∞ —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ (–≤ —Å–∏–º–≤–æ–ª–∞—Ö) –≤ `train_df`?"
      ],
      "metadata": {
        "id": "xf9FQTTmdAbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Cleaned']"
      ],
      "metadata": {
        "id": "wEpHTyTvjO1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_length = train_df['Cleaned'].str.len().mean()\n",
        "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–æ–≤: {average_length:.2f} —Å–∏–º–≤–æ–ª–æ–≤\")"
      ],
      "metadata": {
        "id": "qFdF3MxSnY5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_length = sum(len(text) for text in train_df['Cleaned']) / len(train_df)\n",
        "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–æ–≤: {average_length:.2f} —Å–∏–º–≤–æ–ª–æ–≤\")"
      ],
      "metadata": {
        "id": "hRHEst3vrKCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars = 0\n",
        "num_examples = len(train_df)\n",
        "\n",
        "for example in train_df:\n",
        "    text = train_df['Cleaned']\n",
        "    total_chars += len(text)\n",
        "\n",
        "average_length = total_chars / num_examples\n",
        "\n",
        "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {average_length:.2f} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
        "print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_chars}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {num_examples}\")"
      ],
      "metadata": {
        "id": "gPssEz5-DVJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 4.** –¢–µ–ø–µ—Ä—å —Ä–µ–∞–ª–∏–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞. –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ `Trainer` –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ü§ó –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–≤–æ—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–¥—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ `loss`, –Ω–æ –∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, F1-score, accuracy –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "–ú—ã —Ö–æ—Ç–∏–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics`, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –≤ `Trainer`. –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –∫–æ—Ä—Ç–µ–∂ `(logits, labels)` ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏, –∏ –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å **accuracy** (–¥–æ–ª—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤).\n",
        "\n",
        "**–í–æ–ø—Ä–æ—Å 4.** –ü–æ—á–µ–º—É, –∫—Å—Ç–∞—Ç–∏, –º—ã –≤—ã–±—Ä–∞–ª–∏ –∑–¥–µ—Å—å –∏–º–µ–Ω–Ω–æ **accuracy** –º–µ—Ç—Ä–∏–∫—É?\n",
        "\n"
      ],
      "metadata": {
        "id": "Rp2xv08ieC6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –∑–¥–µ—Å—å –∏–º–ø—É—Ç—ã, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É—é—Ç—Å—è\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    # –≤—Ö–æ–¥: –ø–∞—Ä–∞ (logits, labels)\n",
        "    # –≤–µ—Ä–Ω–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "-Aw-xtCbhT0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}"
      ],
      "metadata": {
        "id": "0noe1E1hD__v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥. –ï—Å–ª–∏ –≤–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞–ø–∏—Å–∞–Ω–∞ –≤–µ—Ä–Ω–æ, —Ç–æ –∫–æ–¥ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –æ—à–∏–±–æ–∫."
      ],
      "metadata": {
        "id": "5rJh7_DbhfKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_logits = np.array([[0.1, 0.9], [0.8, 0.2], [0.4, 0.6]])\n",
        "test_labels = np.array([1, 0, 1])\n",
        "\n",
        "eval_pred = (test_logits, test_labels)\n",
        "\n",
        "metrics = compute_metrics(eval_pred)\n",
        "print(\"Test metrics:\", metrics)\n",
        "\n",
        "assert \"accuracy\" in metrics, \"–§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º 'accuracy'\"\n",
        "assert isinstance(metrics[\"accuracy\"], float), \"–ó–Ω–∞—á–µ–Ω–∏–µ accuracy –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º\"\n",
        "assert abs(metrics[\"accuracy\"] - 1.0) < 1e-6, \"–û–∂–∏–¥–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ accuracy: 1.0 –Ω–∞ –∏–¥–µ–∞–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ\""
      ],
      "metadata": {
        "id": "YNyZTJEChehV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 5.** –†–µ–∞–ª–∏–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –ø–æ–¥–∞–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –≤ –º–æ–¥–µ–ª—å `BERT`, –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏—Ö –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Ç–æ–∫–µ–Ω—ã. –≠—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∂–¥—ã–π –æ—Ç–∑—ã–≤ –≤ –Ω–∞–±–æ—Ä —á–∏—Å–µ–ª, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–¥—Å–ª–æ–≤–Ω—ã–º –µ–¥–∏–Ω–∏—Ü–∞–º, –∫–æ—Ç–æ—Ä—ã–µ `BERT` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–∞–∫ –≤—Ö–æ–¥. –ù–æ –≤–∞–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —á—Ç–æ–±—ã –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –∏–º–µ–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É –∏ –Ω–µ –æ–±—Ä–µ–∑–∞–ª–∏—Å—å –Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ.\n"
      ],
      "metadata": {
        "id": "ong_RgyejIXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `tokenize_function`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∫ –∫–æ–ª–æ–Ω–∫–µ —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏. –ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å *–ø–æ—Å—Ç—Ä–æ—á–Ω—É—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º –∏ —É—Å–µ—á–µ–Ω–∏–µ–º*.\n"
      ],
      "metadata": {
        "id": "bVEsXHCej4YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return # –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥"
      ],
      "metadata": {
        "id": "ad9UmX6uj9lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['Cleaned'], padding='max_length', truncation=True, max_length=128)"
      ],
      "metadata": {
        "id": "yFjK3_NJEmlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–æ–ø—Ä–æ—Å 5.** –ö–∞–∫–æ–π –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –±—É–¥–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Ç–∑—ã–≤–æ–≤?"
      ],
      "metadata": {
        "id": "LJpjYK-AkHzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ä–∞—Å—Å—É–∂–¥–∞–µ–º –Ω–∞—Å—á–µ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `max_length`: –∫–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –º—ã –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ –Ω–∞—à—É –º–æ–¥–µ–ª—å? –ò—Ç–∞–∫, —á—Ç–æ –º—ã —É–∂–µ –∑–Ω–∞–µ–º:\n",
        "1. –º–∞–∫—Å–∏–º—É–º –¥–ª—è `BERT` —ç—Ç–æ `max_length = 512`.\n",
        "2. –í –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ WordPiece (—É `bert-base-uncased`, –Ω–∞–ø—Ä–∏–º–µ—Ä) –∏–∑ 100 —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å—Ä–µ–¥–Ω–µ–º –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ—Ç 20 –¥–æ 40 —Ç–æ–∫–µ–Ω–æ–≤, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–≤, –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ –Ω–∞–ª–∏—á–∏—è —Ä–µ–¥–∫–∏—Ö –ø–æ–¥—Å–ª–æ–≤.\n",
        "\n"
      ],
      "metadata": {
        "id": "8RhwACJdlcrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "text = train_df[\"Cleaned\"].iloc[0]\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print(len(text), \"—Å–∏–º–≤–æ–ª–æ–≤\")\n",
        "print(len(tokens), \"—Ç–æ–∫–µ–Ω–æ–≤\")\n",
        "\n",
        "# 1127 —Å–∏–º–≤–æ–ª–æ–≤\n",
        "# 223 —Ç–æ–∫–µ–Ω–æ–≤"
      ],
      "metadata": {
        "id": "Bu6tRAqJndBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ï—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ ‚Äî –æ–∫–æ–ª–æ 900 —Å–∏–º–≤–æ–ª–æ–≤, —Ç–æ —Ä–∞–∑—É–º–Ω—ã–π –≤—ã–±–æ—Ä:\n",
        "\n",
        "* `max_length = 256` ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏ –±—ã—Å—Ç—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
        "* `max_length = 384` ‚Äî –µ—Å–ª–∏ —Ö–æ—á–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
        "* `max_length = 512` ‚Äî –º–∞–∫—Å–∏–º—É–º –¥–ª—è **BERT**, –Ω–æ:\n",
        "\n",
        "  * —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏\n",
        "  * –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–µ–Ω (–¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤)\n",
        "\n"
      ],
      "metadata": {
        "id": "TlkufTqSoKir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ 6.** –ü–æ–¥–æ–±—Ä–∞–ª–∏—Å—å –º—ã –∏ –∫ –æ–±—É—á–µ–Ω–∏—é. –¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –≤—ã –æ—Å–≤–æ–∏–ª–∏ –≤—Å–µ —ç—Ç–∞–ø—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏, –¥–∞–≤–∞–π—Ç–µ –ø—Ä–∏–º–µ–Ω–∏–º —ç—Ç–∏ –∑–Ω–∞–Ω–∏—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∏ —Å—Ä–∞–≤–Ω–∏–º —Ç—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–∏ BERT –Ω–∞ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Ç–∑—ã–≤–æ–≤.\n",
        "\n"
      ],
      "metadata": {
        "id": "MLF9LX_soXQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–≠—Ç–æ –±—É–¥–µ—Ç —Å–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å - –Ω–æ –∏ —Å–∞–º–∞—è —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–∞—è. –¶–µ–ª—å –∑–∞–¥–∞–Ω–∏—è:\n",
        "\n",
        "1. –ù–∞–ø–∏—Å–∞—Ç—å **–ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏**, –≤–∫–ª—é—á–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é (–ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é, –Ω–∞–ø–∏—Å–∞–Ω–Ω—É—é –≤—ã—à–µ), –æ–±—É—á–µ–Ω–∏–µ, –≤–∞–ª–∏–¥–∞—Ü–∏—é.\n",
        "2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–Ω–ª–∞–π–Ω —Å —Ç—Ä–µ–º—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏:\n",
        "   * `\"bert-base-uncased\"`\n",
        "   * `\"roberta-base\"`\n",
        "   * `\"distilbert-base-uncased\"`\n",
        "3. –û–±—É—á–∏—Ç—å –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å –Ω–∞ 3 —ç–ø–æ—Ö–∞—Ö –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ (`accuracy`).\n",
        "\n",
        "PS –í—ã –º–æ–∂–µ—Ç–µ –Ω–∞–ø–∏—Å–∞—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ, –Ω–æ –±—É–¥–µ—Ç –±–æ–ª–µ–µ –∏–∑—è—â–Ω–æ, –µ—Å–ª–∏ –≤—ã –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –≤—Å—ë –≤ –µ–¥–∏–Ω—ã–π —Ü–∏–∫–ª - –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞."
      ],
      "metadata": {
        "id": "JLlrPhJC17ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> –ü–æ—á–∏—Ç–∞–π—Ç–µ, —á—Ç–æ —Ç–∞–∫–æ–µ [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding:~:text=value%20at%20initialization.-,DataCollatorWithPadding,-class%20transformers.) –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ —Å–≤–æ—ë —Ä–µ—à–µ–Ω–∏–µ."
      ],
      "metadata": {
        "id": "eUSAWmka2LpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è - –ø—É—Å—Ç—å –±—É–¥—É—Ç –µ–¥–∏–Ω—ã, —á—Ç–æ–±—ã –º—ã —Å–æ–≥–ª–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    report_to=\"none\" # –æ—Ç–∫–ª—é—á–∞–µ–º wandb –∏ tensorboard - –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å, –µ—Å–ª–∏ —ç—Ç–æ –Ω—É–∂–Ω–æ\n",
        ")"
      ],
      "metadata": {
        "id": "gtSnhvpEtIyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "JoKeEIPFF7yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "c1f9qsBnGhXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥\n",
        "# (‚åí_‚åí;)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# –ú–µ–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')"
      ],
      "metadata": {
        "id": "fSjaFk-x2F8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/BaseBert',\n",
        "    num_train_epochs=3, # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö - –ø–æ–ª–Ω—ã—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º\n",
        "    per_device_train_batch_size=8, # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU/CPU)\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500, # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ \"—Ä–∞–∑–æ–≥—Ä–µ–≤–∞\" - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ learning rate –≤ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
        "    weight_decay=0.01, # L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ - –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "zGZDbK-JHU3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "aJ3X1t8UHvgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# –ú–µ–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/RoBERT',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "dh9Ju-rbH3wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏ DistilBERT\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# –ú–µ–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/DistilBERT',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "du5IBoN-IUgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ë–æ–Ω—É—Å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ.** –í—ã–±–µ—Ä–µ—Ç–µ –º–æ–¥–µ–ª—å: –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∏–∑ —á–∏—Å–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –∏–ª–∏ –ª—é–±—É—é –¥—Ä—É–≥—É—é - –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏. –ú–æ–∂–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤, —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏, –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ —Ç–¥. –ú–æ–∂–Ω–æ –∏ —É—á–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö - –µ—Å–ª–∏ –≤–∞–º –ø–æ–∑–≤–æ–ª–∏—Ç –≤—Ä–µ–º—è –∏ —Ä–µ—Å—É—Ä—Å—ã.\n",
        "\n",
        "–ù–∞–ø–∏—à–∏—Ç–µ –æ —Å–≤–æ–∏—Ö —É—Å–ø–µ—Ö–∞—Ö –Ω–∞–º –Ω–∞ —Å—Ç–µ–ø–∏–∫–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –ø–æ–¥ –±–æ–Ω—É—Å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º. –ò —Å—Ç—É–¥–µ–Ω—Ç–∞–º, –∏ –Ω–∞–º –±—É–¥–µ—Ç –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø—Ä–æ—á–µ—Å—Ç—å –≤–∞—à–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
      ],
      "metadata": {
        "id": "bcnovl-m0Fyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –∑–¥–µ—Å—å –≤–∞—à –∫–æ–¥\n",
        "# „ÉΩ(‚ô°‚Äø‚ô°)„Éé"
      ],
      "metadata": {
        "id": "zjUIqY0R0FU7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}