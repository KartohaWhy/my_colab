{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KartohaWhy/my_colab/blob/main/Copy_Encoder_decoder_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Практика по работе с Энкодерами"
      ],
      "metadata": {
        "id": "_AOOjGBvtP38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом задании мы потренируемся использовать различные энкодеры под наши задачи. Мы поработаем с классической бинарной классификацией отзывов на фильмы, попробуем усложнить и выйти на многоклассовую задачу, а после - подключим определение семантической близости фильмов по их описанию."
      ],
      "metadata": {
        "id": "R3NteXJrtUdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Бинарная классификация"
      ],
      "metadata": {
        "id": "SFAqdV4v_3_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets transformers"
      ],
      "metadata": {
        "id": "StLV9K1sC-US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "DJFr4QE6C70X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед вами практическое задание по бинарной классификации текстов с использованием предобученной модели BERT. Мы будем решать задачу определения тональности пользовательских отзывов на фильмы — **положительный** отзыв или **отрицательный**.\n",
        "\n",
        "В качестве источника данных используем открытый датасет [IMDb](https://huggingface.co/datasets/stanfordnlp/imdb) от [Stanford NLP](https://nlp.stanford.edu/), содержащий 50 000 англоязычных рецензий, размеченных вручную. Цель — построить и обучить модель, способную автоматически классифицировать тексты по их эмоциональной окраске. Вы пройдёте все основные этапы пайплайна: от очистки текста и токенизации до обучения модели и оценки качества."
      ],
      "metadata": {
        "id": "DJnnmwz1AV5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед тем, как мы двинемся дальше, проверьте включен или выключен GPU в colab. Работа с BERT потребует ресурсов, но предлагаем сначала заполнить весь необходимый код, а потом уже подключить GPU перед самым обучением модели. Советуем использовать доступную в colab Tesla T4."
      ],
      "metadata": {
        "id": "E88AC_Vvu3z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU на месте: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "92FbwW-ovOde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oPy65CbFkpCd"
      },
      "outputs": [],
      "source": [
        "# датасет сразу подгружен в модуль datasets от HF\n",
        "\n",
        "dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "2HKNhUOgEZH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что в датасете уже подготовленное разделение данных на тренировочную и тестовую выборку, а также \"unsupervised\" набор - неразмеченная часть данных — то есть отзывы, у которых нет корректной метки (label не несёт обучающей информации).\n",
        "\n",
        "* В части `train` и `test` у каждого отзыва есть метка: `label = 0` (негативный) или `label = 1` (позитивный).\n",
        "* В части `unsupervised` колонка `label` есть, но её значение не используется — оно либо пустое, либо фиктивное (`-1`), так как эта часть предназначена для:\n",
        "\n",
        "  * обучения без учителя (например, pretraining),\n",
        "  * самостоятельного дообучения языковой модели,\n",
        "  * полу- или слаборазмеченного обучения."
      ],
      "metadata": {
        "id": "_D3oqcxuFAXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"unsupervised\"][0] # лейбл обозначен как \"-1\""
      ],
      "metadata": {
        "id": "0HV8qyOpFjBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В нашей задаче мы не будем использовать `unsupervised` часть — только размеченные данные из `train` и `test`. Точнее, только из `train` - 50.000 объектов на обучение это неплохо, но для учебной задачи долговато. С целью сокращения времени - сократим и датасет."
      ],
      "metadata": {
        "id": "UbxIx2tlGGZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1.** Давайте оставим только `train`, а затем перемешаем его с помщью `shuffle`, а после разобьем на обучающую и валидационную выборки в соотношении 80:20.\n",
        "\n",
        "> Попробуем удержать баланс классов? Установите в гиперпараметре пропорциональное распределение классов. Если не помните, как это выполнить, загляните в описание метода [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ],
      "metadata": {
        "id": "cdsUwKz_GZW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь ваш код\n",
        "# ヽ(♡‿♡)ノ\n",
        "\n",
        "train_data = dataset[\"train\"].to_pandas()\n",
        "shuffled_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "train_df, val_df, = train_test_split(\n",
        "    shuffled_data,\n",
        "    test_size=0.2,\n",
        "    stratify=shuffled_data['label'],  # Важно для баланса классов\n",
        ")"
      ],
      "metadata": {
        "id": "tDXGDov7Hani"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBClfwU6dnYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "ZvOfa29iduG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df"
      ],
      "metadata": {
        "id": "lawAVLLPrv26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ7xbPXSzacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 1.** Сколько отзывов положительного класса `(label = 1)` содержится в `val_df` после разбиения?"
      ],
      "metadata": {
        "id": "6PiD3_6tL9aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2.** **А стоит ли чистить отзывы?**"
      ],
      "metadata": {
        "id": "XvqzvD2URSQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед тем как обучать модель на текстовых данных, важно понять, в каком виде приходят тексты, и нужна ли им предобработка.\n",
        "\n",
        "В нашем случае отзывы взяты напрямую из `IMDb` — они написаны живыми пользователями, без фильтрации и нормализации. Чтобы принять решение об очистке, посмотрите на первые несколько примеров из датасета.\n",
        "\n",
        "Обратите внимание на:\n",
        "\n",
        "* наличие заглавных букв,\n",
        "* пунктуацию (много ли её? нарушает ли она понимание?),\n",
        "* цифры и HTML-теги (встречаются ли? нужны ли они для тональности?),\n",
        "* стоп-слова (могут ли они мешать?)."
      ],
      "metadata": {
        "id": "QMqoi7f7SS_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# посмотрите на первые десять примеров из датасета (можно взять и больше) и поизучайте их\n",
        "\n",
        "# здесь ваш код\n",
        "# (＠_＠)\n",
        "\n",
        "X_train[:10]"
      ],
      "metadata": {
        "id": "IORsy3WnSdBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 2** - на размышление: *Какую базовую предобработку вы бы применили к этим отзывам перед подачей в токенизатор BERT?*\n",
        "\n",
        "> *Важно помнить*: модели `BERT` обучаются на сырых текстах, но легкая очистка всё же может помочь — особенно, если мы визуализируем текст, считаем TF-IDF или хотим сделать простой анализ.\n",
        "\n",
        "В следующем шаге вы напишете функцию очистки текста. Если вы считаете, что некоторые из этих элементов обработки не нужны, всё равно, пожалуйста, выполните их. В бонусном задании вы сможете вернуться к этому вопросу и поэкспериментировать с разными подходами к обработке."
      ],
      "metadata": {
        "id": "NiElShYWS-e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 3.** Теперь почистим наши тексты. Напишите функцию `clean_text`, которая будет очищать текст от лишнего. Вы можете опираться на код с семинара или написать свой вариант. Давайте: 1) приведем к нижнему регистру 2) уберем числа 3) удалим переносы строк 4) уберем стоп-слова.\n",
        "\n",
        "Также удалите из таблицы те строки, где текст отзыва оказался пустым после очистки.\n",
        "\n",
        "Вам здесь пригодятся модули `re`, `string`, `nltk` (`nltk.download('stopwords')`), `stopwords` из `nltk.corpus`. Не забудьте применить обработку и к трейну, и к тесту."
      ],
      "metadata": {
        "id": "SPI-y8rSTXCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # работа с регулярными выражениями (очистка текста)\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "eFQnAY4piPdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь ваш код\n",
        "# (⌒_⌒;)\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Приведение к нижнему регистру\n",
        "    text = re.sub('\\n', ' ', text)  # Удаление переносов строк\n",
        "    text = re.sub('\\d+', '', text)  # Удаление цифр\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Удаление стоп-слов\n",
        "    return text"
      ],
      "metadata": {
        "id": "4q4H614dS9jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление строк с пустыми отзывами\n",
        "val_df.dropna()\n",
        "train_df.dropna()\n",
        "# Стоп-слова\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "train_df['Cleaned'] = train_df['text'].apply(clean_text)\n",
        "val_df['Cleaned'] = val_df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "XJxHNaqjihJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 3.** Чему равна средняя длина очищенных отзывов (в символах) в `train_df`?"
      ],
      "metadata": {
        "id": "xf9FQTTmdAbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Cleaned']"
      ],
      "metadata": {
        "id": "wEpHTyTvjO1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_length = train_df['Cleaned'].str.len().mean()\n",
        "print(f\"Средняя длина отзывов: {average_length:.2f} символов\")"
      ],
      "metadata": {
        "id": "qFdF3MxSnY5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_length = sum(len(text) for text in train_df['Cleaned']) / len(train_df)\n",
        "print(f\"Средняя длина отзывов: {average_length:.2f} символов\")"
      ],
      "metadata": {
        "id": "hRHEst3vrKCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars = 0\n",
        "num_examples = len(train_df)\n",
        "\n",
        "for example in train_df:\n",
        "    text = train_df['Cleaned']\n",
        "    total_chars += len(text)\n",
        "\n",
        "average_length = total_chars / num_examples\n",
        "\n",
        "print(f\"Средняя длина очищенных отзывов: {average_length:.2f} символов\")\n",
        "print(f\"Общее количество символов: {total_chars}\")\n",
        "print(f\"Количество примеров: {num_examples}\")"
      ],
      "metadata": {
        "id": "gPssEz5-DVJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 4.** Теперь реализуем функцию оценки качества. При обучении модели через `Trainer` из библиотеки 🤗 можно передать свою функцию подсчёта метрик. Это позволяет отслеживать не только `loss`, но и, например, F1-score, accuracy или другие метрики качества.\n",
        "\n",
        "\n",
        "Мы хотим реализовать функцию `compute_metrics`, которая будет передаваться в `Trainer`. Эта функция получает на вход кортеж `(logits, labels)` — предсказания модели и реальные метки, и должна возвращать **accuracy** (долю правильных ответов).\n",
        "\n",
        "**Вопрос 4.** Почему, кстати, мы выбрали здесь именно **accuracy** метрику?\n",
        "\n"
      ],
      "metadata": {
        "id": "Rp2xv08ieC6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь импуты, если потребуются\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    # вход: пара (logits, labels)\n",
        "    # верните словарь с точностью\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "-Aw-xtCbhT0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}"
      ],
      "metadata": {
        "id": "0noe1E1hD__v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустите следующий код. Если ваша функция написана верно, то код отработает без ошибок."
      ],
      "metadata": {
        "id": "5rJh7_DbhfKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_logits = np.array([[0.1, 0.9], [0.8, 0.2], [0.4, 0.6]])\n",
        "test_labels = np.array([1, 0, 1])\n",
        "\n",
        "eval_pred = (test_logits, test_labels)\n",
        "\n",
        "metrics = compute_metrics(eval_pred)\n",
        "print(\"Test metrics:\", metrics)\n",
        "\n",
        "assert \"accuracy\" in metrics, \"Функция должна возвращать словарь с ключом 'accuracy'\"\n",
        "assert isinstance(metrics[\"accuracy\"], float), \"Значение accuracy должно быть числом\"\n",
        "assert abs(metrics[\"accuracy\"] - 1.0) < 1e-6, \"Ожидаемое значение accuracy: 1.0 на идеально предсказанном примере\""
      ],
      "metadata": {
        "id": "YNyZTJEChehV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 5.** Реализуем функцию токенизации текста. Перед тем как подавать тексты в модель `BERT`, нужно преобразовать их в числовой формат — токены. Это делает токенизатор модели.\n",
        "\n",
        "Токенизатор превращает каждый отзыв в набор чисел, соответствующих подсловным единицам, которые `BERT` использует как вход. Но важно задать параметры, чтобы все примеры имели одинаковую длину и не обрезались неконтролируемо.\n"
      ],
      "metadata": {
        "id": "ong_RgyejIXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте функцию `tokenize_function`, которая применяет токенизатор к колонке с очищенными отзывами. Мы будем использовать *построчную токенизацию с паддингом и усечением*.\n"
      ],
      "metadata": {
        "id": "bVEsXHCej4YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return # здесь ваш код"
      ],
      "metadata": {
        "id": "ad9UmX6uj9lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['Cleaned'], padding='max_length', truncation=True, max_length=128)"
      ],
      "metadata": {
        "id": "yFjK3_NJEmlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 5.** Какой набор параметров токенизатора будет наиболее подходящим для обучения модели классификации отзывов?"
      ],
      "metadata": {
        "id": "LJpjYK-AkHzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь давайте немного порассуждаем насчет гиперпараметра `max_length`: какое количество токенов мы будет отправлять в нашу модель? Итак, что мы уже знаем:\n",
        "1. максимум для `BERT` это `max_length = 512`.\n",
        "2. В английском языке при использовании токенизации WordPiece (у `bert-base-uncased`, например) из 100 символов в среднем получается от 20 до 40 токенов, в зависимости от слов, пунктуации и наличия редких подслов.\n",
        "\n"
      ],
      "metadata": {
        "id": "8RhwACJdlcrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# давайте проверим\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "text = train_df[\"Cleaned\"].iloc[0]\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print(len(text), \"символов\")\n",
        "print(len(tokens), \"токенов\")\n",
        "\n",
        "# 1127 символов\n",
        "# 223 токенов"
      ],
      "metadata": {
        "id": "Bu6tRAqJndBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если средняя длина отзывов после очистки — около 900 символов, то разумный выбор:\n",
        "\n",
        "* `max_length = 256` — безопасный и быстрый вариант\n",
        "* `max_length = 384` — если хочется сохранить больше контекста\n",
        "* `max_length = 512` — максимум для **BERT**, но:\n",
        "\n",
        "  * увеличивает время и потребление памяти\n",
        "  * может быть избыточен (для коротких отзывов)\n",
        "\n"
      ],
      "metadata": {
        "id": "TlkufTqSoKir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 6.** Подобрались мы и к обучению. Теперь, когда вы освоили все этапы предобработки, токенизации и настройки модели, давайте применим эти знания на практике и сравним три разных версии BERT на задаче классификации отзывов.\n",
        "\n"
      ],
      "metadata": {
        "id": "MLF9LX_soXQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это будет самая сложная часть - но и самая содержательная. Цель задания:\n",
        "\n",
        "1. Написать **полный пайплайн обучения модели**, включая токенизацию (подтягиваем нашу функцию, написанную выше), обучение, валидацию.\n",
        "2. Запустить пайнлайн с тремя предобученными моделями:\n",
        "   * `\"bert-base-uncased\"`\n",
        "   * `\"roberta-base\"`\n",
        "   * `\"distilbert-base-uncased\"`\n",
        "3. Обучить каждую модель на 3 эпохах и сравнить метрику качества (`accuracy`).\n",
        "\n",
        "PS Вы можете написать логику для каждой модели отдельно, но будет более изящно, если вы объедините всё в единый цикл - без лишнего дублирования кода."
      ],
      "metadata": {
        "id": "JLlrPhJC17ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Почитайте, что такое [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding:~:text=value%20at%20initialization.-,DataCollatorWithPadding,-class%20transformers.) и попробуйте интегрировать в своё решение."
      ],
      "metadata": {
        "id": "eUSAWmka2LpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Аргументы обучения - пусть будут едины, чтобы мы согли синхронизировать результаты\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    report_to=\"none\" # отключаем wandb и tensorboard - вы можете подключить, если это нужно\n",
        ")"
      ],
      "metadata": {
        "id": "gtSnhvpEtIyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "JoKeEIPFF7yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "c1f9qsBnGhXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь ваш код\n",
        "# (⌒_⌒;)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Меняем название, поскольку модель ожидает название \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')"
      ],
      "metadata": {
        "id": "fSjaFk-x2F8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/BaseBert',\n",
        "    num_train_epochs=3, # количество эпох - полных проходов по тренировочным данным\n",
        "    per_device_train_batch_size=8, # размер батча на одно устройство (GPU/CPU)\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500, # количество шагов \"разогрева\" - постепенное увеличение learning rate в начале обучения\n",
        "    weight_decay=0.01, # L2-регуляризация для весов модели - для борьбы с переобучением\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "zGZDbK-JHU3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "aJ3X1t8UHvgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Меняем название, поскольку модель ожидает название \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/RoBERT',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "dh9Ju-rbH3wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "# Загрузка токенизатора и модели DistilBERT\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['text', 'Cleaned'])\n",
        "val_dataset = val_dataset.remove_columns(['text', 'Cleaned'])\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Меняем название, поскольку модель ожидает название \"labels\"\n",
        "train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "val_dataset = val_dataset.rename_column('label', 'labels')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/DistilBERT',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "du5IBoN-IUgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Бонусное задание.** Выберете модель: можно взять из числа предложенных или любую другую - и попробуйте максимально увеличить метрики на валидации. Можно экспериментировать с методами обработки текстов, с архитектурами модели, подбором гиперпараметров и тд. Можно и учеличить объем данных - если вам позволит время и ресурсы.\n",
        "\n",
        "Напишите о своих успехах нам на степике в комментариях под бонусным вопросом. И студентам, и нам будет очень интересно прочесть ваши эксперименты и результаты."
      ],
      "metadata": {
        "id": "bcnovl-m0Fyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь ваш код\n",
        "# ヽ(♡‿♡)ノ"
      ],
      "metadata": {
        "id": "zjUIqY0R0FU7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}